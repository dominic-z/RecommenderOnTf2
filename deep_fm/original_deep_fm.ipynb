{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 忠于原版paper的deepfm算法\n",
    "# 大量参照https://github.com/ChenglongChen/tensorflow-DeepFM\n",
    "# 该版对deep fm进行了一点点优化，虽然数据描述不太明白，但是其数据结构设计得确实好，很精简也非常适合这个算法\n",
    "# 只能处理one-hot类型的，无法直接处理multi-hot特征\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 0 1]\n",
      " [1 0 2]\n",
      " [1 1 1]\n",
      " [1 1 2]\n",
      " [2 1 2]\n",
      " [3 0 0]\n",
      " [3 0 1]\n",
      " [3 0 2]\n",
      " [3 1 1]\n",
      " [3 1 2]\n",
      " [4 0 0]\n",
      " [4 0 1]\n",
      " [4 0 2]\n",
      " [4 1 0]\n",
      " [4 1 1]\n",
      " [4 1 2]], shape=(16, 3), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "def dense_to_sparse(dense_arr):\n",
    "    arr_idx=tf.where(tf.not_equal(dense_arr,0))\n",
    "    arr_value=tf.gather_nd(dense_arr,indices=arr_idx)\n",
    "    return tf.sparse.SparseTensor(indices=arr_idx,values=arr_value,dense_shape=dense_arr.shape)\n",
    "dense_arr=np.random.choice([0,1],size=[5,2,3])\n",
    "\n",
    "sparse_vec=dense_to_sparse(dense_arr)\n",
    "print(sparse_vec.indices)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_indices_arr\n",
      "[[1. 5. 8.]\n",
      " [5. 1. 8.]\n",
      " [5. 6. 7.]\n",
      " [4. 1. 6.]\n",
      " [2. 0. 5.]\n",
      " [9. 0. 1.]\n",
      " [9. 5. 2.]\n",
      " [9. 7. 5.]\n",
      " [1. 8. 3.]]\n",
      "\n",
      "feat_vals_arr\n",
      "[[1.         1.         0.22750117]\n",
      " [1.         1.         0.69304883]\n",
      " [1.         1.         0.93436545]\n",
      " [1.         1.         0.37342307]\n",
      " [1.         1.         0.88280267]\n",
      " [1.         1.         0.7764623 ]\n",
      " [1.         1.         0.72561693]\n",
      " [1.         1.         0.12427583]\n",
      " [1.         1.         0.7329876 ]]\n",
      "\n",
      "emb vectors\n",
      "tf.Tensor(\n",
      "[[[-0.01592321  0.04625168 -0.00633299 -0.00438272]\n",
      "  [ 0.02244916  0.01049845 -0.01530216 -0.0356332 ]\n",
      "  [-0.00695882  0.00586648  0.00474543  0.00901506]]\n",
      "\n",
      " [[ 0.02244916  0.01049845 -0.01530216 -0.0356332 ]\n",
      "  [-0.01592321  0.04625168 -0.00633299 -0.00438272]\n",
      "  [-0.02119902  0.01787137  0.01445627  0.02746307]]\n",
      "\n",
      " [[ 0.02244916  0.01049845 -0.01530216 -0.0356332 ]\n",
      "  [ 0.01438514  0.04810609 -0.02376117 -0.04308121]\n",
      "  [-0.01193211 -0.0351358   0.00436887  0.03149073]]\n",
      "\n",
      " [[-0.00356496  0.01559236 -0.01409332 -0.01741096]\n",
      "  [-0.01592321  0.04625168 -0.00633299 -0.00438272]\n",
      "  [ 0.00537174  0.01796392 -0.00887297 -0.01608752]]\n",
      "\n",
      " [[ 0.02919188 -0.0340256  -0.04473584 -0.04465357]\n",
      "  [ 0.03187427  0.01491931 -0.03175358 -0.03084992]\n",
      "  [ 0.01981818  0.00926806 -0.01350879 -0.03145708]]], shape=(5, 3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "class EmbeddingLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,feat_dim,field_num,emb_dim,*args,**kwargs):\n",
    "        super(EmbeddingLayer,self).__init__(*args,**kwargs)\n",
    "        self.feat_dim=feat_dim\n",
    "        self.field_num=field_num\n",
    "        self.emb_dim=emb_dim\n",
    "        self.emb_layer=tf.keras.layers.Embedding(input_dim=feat_dim,output_dim=emb_dim)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        # TODO: shape校验\n",
    "        # feat_indices_batch: [batch_size, field_num]\n",
    "        # feat_value_batch: [batch_size, field_num]\n",
    "        feat_indices_batch,feat_value_batch=inputs\n",
    "        emb_vectors=self.emb_layer(feat_indices_batch) # [batch_size, field_num, emb_dim]\n",
    "        feat_value_batch = tf.expand_dims(feat_value_batch,axis=-1) # [batch_size, field_num, 1]\n",
    "\n",
    "        # broadcast性质 feat_value_batch会被看做[batch_size, field_num, emb_dim]\n",
    "        emb_vectors = tf.multiply(emb_vectors,feat_value_batch) # [batch_size, field_num, emb_dim]\n",
    "        return emb_vectors\n",
    "\n",
    "\n",
    "feat_indices_arr=[np.random.choice(range(10),size=[1,3],replace=False) for _ in range(9)]\n",
    "feat_indices_arr=np.concatenate(feat_indices_arr,axis=0).astype(np.float32)\n",
    "print(\"feat_indices_arr\")\n",
    "print(feat_indices_arr) #[10,3]\n",
    "\n",
    "feat_vals_arr=np.concatenate((np.ones(shape=[9,2]),\n",
    "                              np.random.random(size=[9,1])),axis=1).astype(np.float32)\n",
    "print(\"\\nfeat_vals_arr\")\n",
    "print(feat_vals_arr) # [10,3]\n",
    "\n",
    "input_ds=tf.data.Dataset.from_tensor_slices((feat_indices_arr,feat_vals_arr))\n",
    "batched_ds=input_ds.batch(5)\n",
    "iterator=iter(batched_ds)\n",
    "input_batch=next(iterator)\n",
    "\n",
    "\n",
    "print(\"\\nemb vectors\")\n",
    "emb_layer=EmbeddingLayer(feat_dim=10,field_num=3,emb_dim=4)\n",
    "emb_vectors=emb_layer(input_batch)\n",
    "print(emb_vectors)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "emb vectors\n",
      "tf.Tensor(\n",
      "[[[ 0.02489461 -0.02386521 -0.04749582  0.04054957]\n",
      "  [ 0.04825819 -0.03720685 -0.04512548  0.00939973]\n",
      "  [ 0.01470658  0.02836223  0.02684775  0.00979074]]\n",
      "\n",
      " [[ 0.02489461 -0.02386521 -0.04749582  0.04054957]\n",
      "  [-0.03521531  0.02770623  0.01329539 -0.03449791]\n",
      "  [ 0.02877749 -0.02218731 -0.02690938  0.00560528]]\n",
      "\n",
      " [[ 0.04825819 -0.03720685 -0.04512548  0.00939973]\n",
      "  [ 0.04365252  0.00850331 -0.01026509 -0.03003721]\n",
      "  [-0.03128958  0.01953156  0.02513872  0.02865577]]\n",
      "\n",
      " [[-0.03084838 -0.01343482  0.0164963  -0.03938312]\n",
      "  [ 0.04825819 -0.03720685 -0.04512548  0.00939973]\n",
      "  [-0.00449583  0.00280638  0.00361204  0.00411739]]\n",
      "\n",
      " [[ 0.02489461 -0.02386521 -0.04749582  0.04054957]\n",
      "  [ 0.04365252  0.00850331 -0.01026509 -0.03003721]\n",
      "  [ 0.01352484  0.0260832   0.02469041  0.00900401]]], shape=(5, 3, 4), dtype=float32)\n",
      "\n",
      "fm_outputs\n",
      "tf.Tensor(\n",
      "[[-0.9297599 ]\n",
      " [ 0.84937   ]\n",
      " [-1.4519227 ]\n",
      " [-0.505102  ]\n",
      " [ 0.73261493]], shape=(5, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "class FMLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,feat_dim,field_num,emb_dim,*args,**kwargs):\n",
    "        super(FMLayer,self).__init__(*args,**kwargs)\n",
    "        self.feat_dim=feat_dim\n",
    "        self.field_num=field_num\n",
    "        self.emb_dim=emb_dim\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w=tf.Variable(initial_value=tf.random.truncated_normal(shape=[self.feat_dim,]))\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        raw_input_batch,emb_vectors=inputs # emb_vectors: [batch_size, field_num, emb_dim]\n",
    "        # feat_indices_batch: [batch_size, field_num]\n",
    "        # feat_value_batch: [batch_size, field_num]\n",
    "        feat_indices_batch,feat_value_batch=raw_input_batch\n",
    "\n",
    "        # first order term\n",
    "        weights=tf.nn.embedding_lookup(params=self.w,ids=tf.cast(feat_indices_batch,tf.int32)) # [batch_size, field_num]\n",
    "        first_order_term = tf.multiply(feat_value_batch,weights) # [batch_size, field_num]\n",
    "        first_order_term = tf.reduce_sum(first_order_term,axis=1,keepdims=True) # [batch_size, 1]\n",
    "\n",
    "        # second order term\n",
    "        sum_square=tf.square(tf.reduce_sum(emb_vectors,axis=1))\n",
    "        square_sum=tf.reduce_sum(tf.square(emb_vectors),axis=1)\n",
    "\n",
    "        # 下面这个是fm算法的优化算法\n",
    "        second_order_term=1/2*tf.reduce_sum(tf.subtract(sum_square,square_sum),axis=1)\n",
    "        second_order_term=tf.expand_dims(second_order_term,axis=1)\n",
    "        y_fm=first_order_term+second_order_term\n",
    "        return y_fm\n",
    "\n",
    "feat_indices_arr=[np.random.choice(range(10),size=[1,3],replace=False) for _ in range(9)]\n",
    "feat_indices_arr=np.concatenate(feat_indices_arr,axis=0).astype(np.float32)\n",
    "feat_vals_arr=np.concatenate((np.ones(shape=[9,2]),\n",
    "                              np.random.random(size=[9,1])),axis=1).astype(np.float32)\n",
    "\n",
    "input_ds=tf.data.Dataset.from_tensor_slices((feat_indices_arr,feat_vals_arr))\n",
    "batched_ds=input_ds.batch(5)\n",
    "iterator=iter(batched_ds)\n",
    "input_batch=next(iterator)\n",
    "\n",
    "\n",
    "print(\"\\nemb vectors\")\n",
    "emb_layer=EmbeddingLayer(feat_dim=10,field_num=3,emb_dim=4)\n",
    "emb_vectors=emb_layer(input_batch)\n",
    "print(emb_vectors)\n",
    "\n",
    "fm_layer=FMLayer(feat_dim=10,field_num=3,emb_dim=4)\n",
    "fm_inputs=(input_batch,emb_vectors)\n",
    "fm_outputs=fm_layer(fm_inputs)\n",
    "print(\"\\nfm_outputs\")\n",
    "print(fm_outputs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "class DeepLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,deep_units_list,*args,**kwargs):\n",
    "        super(DeepLayer,self).__init__(*args,**kwargs)\n",
    "        self.deep_layers=list()\n",
    "        for deep_units in deep_units_list:\n",
    "            self.deep_layers.append(tf.keras.layers.Dense(units=deep_units,activation=tf.nn.relu))\n",
    "        self.scoring_layer=tf.keras.layers.Dense(units=1,activation=tf.nn.relu)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        for deep_layer in self.deep_layers:\n",
    "            inputs=deep_layer(inputs)\n",
    "        outputs = self.scoring_layer(inputs)\n",
    "        return outputs\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.01890573  0.04296117  0.03233263 -0.04805861]\n",
      "  [-0.00401281  0.01027155 -0.01681412  0.04870746]\n",
      "  [ 0.01037515 -0.00313324 -0.01197792  0.01268558]]\n",
      "\n",
      " [[ 0.02296251  0.04572517  0.0490911   0.00429296]\n",
      "  [-0.00401281  0.01027155 -0.01681412  0.04870746]\n",
      "  [-0.01334891  0.00499446  0.00732018 -0.0024337 ]]\n",
      "\n",
      " [[ 0.01820922 -0.00549909 -0.02102221  0.02226422]\n",
      "  [-0.04842376 -0.04937391 -0.03473265  0.02533804]\n",
      "  [-0.00309319  0.00702892  0.00528998 -0.00786292]]\n",
      "\n",
      " [[-0.04842376 -0.04937391 -0.03473265  0.02533804]\n",
      "  [-0.00541728  0.02113969  0.04591503  0.01909229]\n",
      "  [-0.01048983  0.02383698  0.01793974 -0.02666529]]\n",
      "\n",
      " [[ 0.01820922 -0.00549909 -0.02102221  0.02226422]\n",
      "  [-0.00541728  0.02113969  0.04591503  0.01909229]\n",
      "  [-0.01871847 -0.01908576 -0.0134261   0.00979456]]], shape=(5, 3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.01890573  0.04296117  0.03233263 -0.04805861 -0.00401281  0.01027155\n",
      "  -0.01681412  0.04870746  0.01037515 -0.00313324 -0.01197792  0.01268558]\n",
      " [ 0.02296251  0.04572517  0.0490911   0.00429296 -0.00401281  0.01027155\n",
      "  -0.01681412  0.04870746 -0.01334891  0.00499446  0.00732018 -0.0024337 ]\n",
      " [ 0.01820922 -0.00549909 -0.02102221  0.02226422 -0.04842376 -0.04937391\n",
      "  -0.03473265  0.02533804 -0.00309319  0.00702892  0.00528998 -0.00786292]\n",
      " [-0.04842376 -0.04937391 -0.03473265  0.02533804 -0.00541728  0.02113969\n",
      "   0.04591503  0.01909229 -0.01048983  0.02383698  0.01793974 -0.02666529]\n",
      " [ 0.01820922 -0.00549909 -0.02102221  0.02226422 -0.00541728  0.02113969\n",
      "   0.04591503  0.01909229 -0.01871847 -0.01908576 -0.0134261   0.00979456]], shape=(5, 12), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(5, 1), dtype=float32, numpy=\narray([[0.8164731 ],\n       [0.778374  ],\n       [0.9368044 ],\n       [0.84344083],\n       [0.8501859 ]], dtype=float32)>"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DeepFM(tf.keras.Model):\n",
    "    def __init__(self,feat_dim,field_num,emb_dim,deep_units_list,*args,**kwargs):\n",
    "        super(DeepFM,self).__init__(*args,**kwargs)\n",
    "\n",
    "        self.emb_layer=EmbeddingLayer(feat_dim=feat_dim,field_num=field_num,emb_dim=emb_dim)\n",
    "        self.fm_layer=FMLayer(feat_dim=feat_dim,field_num=field_num,emb_dim=emb_dim)\n",
    "        self.deep_layer=DeepLayer(deep_units_list=deep_units_list)\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        emb_vectors=self.emb_layer(inputs)\n",
    "\n",
    "        fm_inputs=(inputs,emb_vectors)\n",
    "        y_fm=self.fm_layer(fm_inputs)\n",
    "\n",
    "        deep_inputs=tf.reshape(emb_vectors,shape=[emb_vectors.shape[0],-1])\n",
    "        y_deep=self.deep_layer(deep_inputs)\n",
    "        y=tf.nn.sigmoid(y_fm+y_deep)\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "feat_indices_arr=[np.random.choice(range(10),size=[1,3],replace=False) for _ in range(9)]\n",
    "feat_indices_arr=np.concatenate(feat_indices_arr,axis=0).astype(np.float32)\n",
    "feat_vals_arr=np.concatenate((np.ones(shape=[9,2]),\n",
    "                              np.random.random(size=[9,1])),axis=1).astype(np.float32)\n",
    "\n",
    "input_ds=tf.data.Dataset.from_tensor_slices((feat_indices_arr,feat_vals_arr))\n",
    "batched_ds=input_ds.batch(5)\n",
    "iterator=iter(batched_ds)\n",
    "input_batch=next(iterator)\n",
    "\n",
    "deep_fm_model=DeepFM(feat_dim=10,field_num=3,emb_dim=4,deep_units_list=[10,8])\n",
    "deep_fm_model(input_batch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\narray([[0., 5., 7.],\n       [2., 1., 7.],\n       [5., 8., 7.],\n       [1., 3., 6.],\n       [5., 9., 8.]], dtype=float32)>"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(15, 2), dtype=int64, numpy=\narray([[0, 0],\n       [0, 1],\n       [0, 2],\n       [1, 0],\n       [1, 1],\n       [1, 2],\n       [2, 0],\n       [2, 1],\n       [2, 2],\n       [3, 0],\n       [3, 1],\n       [3, 2],\n       [4, 0],\n       [4, 1],\n       [4, 2]])>"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\narray([[1.        , 1.        , 0.2890967 ],\n       [1.        , 1.        , 0.23226215],\n       [1.        , 1.        , 0.59886897],\n       [1.        , 1.        , 0.3583779 ],\n       [1.        , 1.        , 0.90877706]], dtype=float32)>"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}